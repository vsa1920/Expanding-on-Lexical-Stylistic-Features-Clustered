{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"19VCq2c0oZSo9f283YxCZrMRFU_lzleSi","timestamp":1703034746923}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1873c84a63094d2f8fc4fdd2c50c36f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6702d1cbbacd4b2a8ef80b45d8cd15b5","IPY_MODEL_a53c8f7a3d354e0f91dd56a9efb34a5f","IPY_MODEL_8f5a7910dbaa481f918fabe715c601b0"],"layout":"IPY_MODEL_b1fff4dc8cb64f51a53523dbc2c56011"}},"6702d1cbbacd4b2a8ef80b45d8cd15b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f85200085a44c958835a80d4829072c","placeholder":"​","style":"IPY_MODEL_ec1c6e8fd5254f49a7c4f4ec598a7e79","value":"config.json: 100%"}},"a53c8f7a3d354e0f91dd56a9efb34a5f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_989f103e6cf54941b47f9d612b9fb432","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52f1a1ce29724bbbbb9bc3e8749b6db7","value":625}},"8f5a7910dbaa481f918fabe715c601b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_604abbfcccac42bc8c7901f511a3fea7","placeholder":"​","style":"IPY_MODEL_ab82c2886bf64424a9c59cee4d0704a7","value":" 625/625 [00:00&lt;00:00, 32.3kB/s]"}},"b1fff4dc8cb64f51a53523dbc2c56011":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f85200085a44c958835a80d4829072c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec1c6e8fd5254f49a7c4f4ec598a7e79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"989f103e6cf54941b47f9d612b9fb432":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52f1a1ce29724bbbbb9bc3e8749b6db7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"604abbfcccac42bc8c7901f511a3fea7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab82c2886bf64424a9c59cee4d0704a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"204a1170e7b6474db05e7dd2ad9cb20a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e70fb4c1bf2b455983744afc71eda026","IPY_MODEL_faf6e76b6bbc4a1c831779d3f3af680d","IPY_MODEL_0c43c38edf054eeaac39bfc3bd71645c"],"layout":"IPY_MODEL_c0dea67dc1b849638b09e08df2f48998"}},"e70fb4c1bf2b455983744afc71eda026":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_666f097e6d2041e1ab84ba5f05829475","placeholder":"​","style":"IPY_MODEL_c2bd1cc6ad0c43cebf4b80b6060ef061","value":"model.safetensors: 100%"}},"faf6e76b6bbc4a1c831779d3f3af680d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_00664114fd1642649974cc6347bceba0","max":672247920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a426b1aca774dc0bae637f92e83d975","value":672247920}},"0c43c38edf054eeaac39bfc3bd71645c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9315aab1b3e3460899d1416aa760f1e8","placeholder":"​","style":"IPY_MODEL_053e3a5ca9ae4824a5375d18ec40d82e","value":" 672M/672M [00:05&lt;00:00, 215MB/s]"}},"c0dea67dc1b849638b09e08df2f48998":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"666f097e6d2041e1ab84ba5f05829475":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2bd1cc6ad0c43cebf4b80b6060ef061":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00664114fd1642649974cc6347bceba0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a426b1aca774dc0bae637f92e83d975":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9315aab1b3e3460899d1416aa760f1e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"053e3a5ca9ae4824a5375d18ec40d82e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74a9a3d477c4476ca6135f079b1f5bbd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7090a2d743ca49a7836fe9e3b6c1d777","IPY_MODEL_9da8879780074a3cb62b86a67830dd33","IPY_MODEL_8b73ca06aee341e1b0031b8b9e8547ab"],"layout":"IPY_MODEL_9c00f5822fac42b28e636cd5d3f2d7a2"}},"7090a2d743ca49a7836fe9e3b6c1d777":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f186f9e030d423f827acce140cc7c79","placeholder":"​","style":"IPY_MODEL_e2860d9b389342ed9f561168ad2cfbc8","value":"tokenizer_config.json: 100%"}},"9da8879780074a3cb62b86a67830dd33":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcf716647c044886b26adb163fec2d91","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f732076cad444afcbba6bf167d1b0034","value":28}},"8b73ca06aee341e1b0031b8b9e8547ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e8075b1ce79450daec16aa3ca487bb8","placeholder":"​","style":"IPY_MODEL_07eb55959fdd480aba00eb882a0b9b9b","value":" 28.0/28.0 [00:00&lt;00:00, 1.67kB/s]"}},"9c00f5822fac42b28e636cd5d3f2d7a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f186f9e030d423f827acce140cc7c79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2860d9b389342ed9f561168ad2cfbc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcf716647c044886b26adb163fec2d91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f732076cad444afcbba6bf167d1b0034":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e8075b1ce79450daec16aa3ca487bb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07eb55959fdd480aba00eb882a0b9b9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"657e9d59bb15415895b5aab36a3c21e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffd8a5d0a56d4845bf1ddf0d41ff58dd","IPY_MODEL_ca643a81751045c58b89a9f588c1272b","IPY_MODEL_42005054ce4048358d855c80e1dc0d5d"],"layout":"IPY_MODEL_a71498ed7e964102b04d4dacc5d97a56"}},"ffd8a5d0a56d4845bf1ddf0d41ff58dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23fedc2483f341d8b4b4d481a106f5b3","placeholder":"​","style":"IPY_MODEL_ecda7b2ec1554095902f6316bbe5b3f9","value":"vocab.txt: 100%"}},"ca643a81751045c58b89a9f588c1272b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a59a85480be408e972c7c39e2aeb2af","max":871891,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0eba3fd745774ca7b73c71ef1cfb0031","value":871891}},"42005054ce4048358d855c80e1dc0d5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27311f5eb1c6433e9e9b302bf090b0a6","placeholder":"​","style":"IPY_MODEL_2d56e222eb994e4b8b283df5b88e494c","value":" 872k/872k [00:00&lt;00:00, 6.44MB/s]"}},"a71498ed7e964102b04d4dacc5d97a56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23fedc2483f341d8b4b4d481a106f5b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecda7b2ec1554095902f6316bbe5b3f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a59a85480be408e972c7c39e2aeb2af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eba3fd745774ca7b73c71ef1cfb0031":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27311f5eb1c6433e9e9b302bf090b0a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d56e222eb994e4b8b283df5b88e494c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2db2df3d02ff4e639b98ec2513568aa5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e41af63109284e7b993beada3e3fc767","IPY_MODEL_d311ae0203184ae8811f427e41694988","IPY_MODEL_5661d4b53a8d43c2b0167fe4f2dfdb8f"],"layout":"IPY_MODEL_d73736dcbbb64002ae492c2b4d6c4c77"}},"e41af63109284e7b993beada3e3fc767":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d97ed6e53d5d45218e94abd4bb4016ac","placeholder":"​","style":"IPY_MODEL_9e7eb67781ed4e409e29f8aab684ae60","value":"tokenizer.json: 100%"}},"d311ae0203184ae8811f427e41694988":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d2f70bbc0764f3aa143aa83e8a69abf","max":1715180,"min":0,"orientation":"horizontal","style":"IPY_MODEL_49df78b85a8041fd86da9889854a7798","value":1715180}},"5661d4b53a8d43c2b0167fe4f2dfdb8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e033e88e504f45c3ac5f18a6b335b3d2","placeholder":"​","style":"IPY_MODEL_5bb22748772c4deb800bd9fbff2b6ee3","value":" 1.72M/1.72M [00:00&lt;00:00, 5.24MB/s]"}},"d73736dcbbb64002ae492c2b4d6c4c77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d97ed6e53d5d45218e94abd4bb4016ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e7eb67781ed4e409e29f8aab684ae60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d2f70bbc0764f3aa143aa83e8a69abf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49df78b85a8041fd86da9889854a7798":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e033e88e504f45c3ac5f18a6b335b3d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bb22748772c4deb800bd9fbff2b6ee3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Notice\n","This notebook runs experiments for Extension 2. There is no markdown file since everything can be run in this notebook."],"metadata":{"id":"2CGM-cypCgYA"}},{"cell_type":"code","source":["!gdown 1Dom7tohfPJOfryscj6TsdTrxlqJwKCb4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KEpMOFYu3md6","executionInfo":{"status":"ok","timestamp":1703220965366,"user_tz":300,"elapsed":4207,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"84f2b01b-18d2-417a-f871-0b7f27e8a5a4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1Dom7tohfPJOfryscj6TsdTrxlqJwKCb4\n","To: /content/Expanding-on-Lexical-Stylistic-Features-modified.tar.gz\n","100% 84.5M/84.5M [00:02<00:00, 37.6MB/s]\n"]}]},{"cell_type":"code","source":["!tar -xvzf Expanding-on-Lexical-Stylistic-Features-modified.tar.gz"],"metadata":{"id":"zEkHdB8m4fu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","import pandas as pd"],"metadata":{"id":"HWiVrraIpCsA","executionInfo":{"status":"ok","timestamp":1703221033500,"user_tz":300,"elapsed":683,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!python -m spacy download en_core_web_md"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0rsUWD-kpFwi","executionInfo":{"status":"ok","timestamp":1703221055088,"user_tz":300,"elapsed":20140,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"b4e0898d-a806-45c2-ff63-2f786b263ca5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-12-22 04:57:20.499263: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-22 04:57:20.499316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-22 04:57:20.500840: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-22 04:57:20.508196: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-22 04:57:21.989554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-12-22 04:57:23.981036: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 04:57:23.981490: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2023-12-22 04:57:23.981660: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","Collecting en-core-web-md==3.6.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.6.0) (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.10.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2023.11.17)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.1.3)\n","Installing collected packages: en-core-web-md\n","Successfully installed en-core-web-md-3.6.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_md')\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qZfqGvwpNb1","executionInfo":{"status":"ok","timestamp":1703221065433,"user_tz":300,"elapsed":9257,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"ccc9f670-80b4-4494-853a-7e93178dfa95"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"]}]},{"cell_type":"markdown","source":["# Grabbing Data"],"metadata":{"id":"l3a7Ze3NqrML"}},{"cell_type":"code","source":["cd \"Expanding-on-Lexical-Stylistic-Features-modified/source/predict\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nnUYJQDTpUWM","executionInfo":{"status":"ok","timestamp":1703221067129,"user_tz":300,"elapsed":3,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"8c861176-b682-4508-f5d3-6b524523088a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Expanding-on-Lexical-Stylistic-Features-modified/source/predict\n"]}]},{"cell_type":"code","source":["train_unprocessed_data_path = \"/content/Expanding-on-Lexical-Stylistic-Features-modified/data/complexity/SimplePPDB/raw/training-pairs.csv\"\n","val_data_path = '/content/Expanding-on-Lexical-Stylistic-Features-modified/data/complexity/SimplePPDB/val.csv'\n","test_data_path = \"/content/Expanding-on-Lexical-Stylistic-Features-modified/data/complexity/SimplePPDB/test.csv\""],"metadata":{"id":"cs0vrR0npcJJ","executionInfo":{"status":"ok","timestamp":1703221130259,"user_tz":300,"elapsed":142,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Load and preprocess training data\n","train_df = pd.read_csv(train_unprocessed_data_path)\n","test_data_df = pd.read_csv(test_data_path)\n","val_data_df = pd.read_csv(val_data_path)"],"metadata":{"id":"QZIQ9VbepfHm","executionInfo":{"status":"ok","timestamp":1703221132017,"user_tz":300,"elapsed":172,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_df[\"gold_simple\"] = train_df.apply(lambda x: 0 if x['x'] == x['gold'].split('=')[1].strip(\"\\\"\") else 1, axis=1)"],"metadata":{"id":"Rj4N-Vffpqkh","executionInfo":{"status":"ok","timestamp":1703221134004,"user_tz":300,"elapsed":160,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train_df = train_df[[\"x\", \"y\", \"gold_simple\"]]\n","train_data_df = train_df.rename(columns={\"x\": \"0\", \"y\": \"1\"})"],"metadata":{"id":"V-xbFSq0ptN1","executionInfo":{"status":"ok","timestamp":1703221134966,"user_tz":300,"elapsed":1,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Remove data from validation and test\n","train_concat = pd.concat([train_data_df, val_data_df, val_data_df, test_data_df, test_data_df])\n","train_data_df = train_concat.drop_duplicates(keep=False)"],"metadata":{"id":"LAPPf_9kpv07","executionInfo":{"status":"ok","timestamp":1703221135977,"user_tz":300,"elapsed":144,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Save processed training data\n","train_data_df.to_csv(\"/content/Expanding-on-Lexical-Stylistic-Features-modified/data/complexity/SimplePPDB/train.csv\")\n","train_data_path = \"/content/Expanding-on-Lexical-Stylistic-Features-modified/data/complexity/SimplePPDB/train.csv\""],"metadata":{"id":"gHviM826qNLp","executionInfo":{"status":"ok","timestamp":1703221148700,"user_tz":300,"elapsed":145,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Prepare Dataset"],"metadata":{"id":"xUYBpeONq7bM"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"6Fph2e7cmdL2","executionInfo":{"status":"ok","timestamp":1703221152933,"user_tz":300,"elapsed":2288,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","source":["from transformers import AutoModel, AutoTokenizer\n","import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","import csv\n","import spacy\n","import numpy as np"],"metadata":{"id":"AZqwoj5Yn4eD","executionInfo":{"status":"ok","timestamp":1703221159250,"user_tz":300,"elapsed":5169,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def load_dataset(dataset_frn):\n","    if dataset_frn.endswith('.csv'):\n","        delimiter = ','\n","    elif dataset_frn.endswith('.tsv'):\n","        delimiter = '\\t'\n","    else:\n","        raise ValueError(\"Unknown dataset file format.\")\n","    with open(dataset_frn, 'r', encoding='utf-8') as dataset_fr:\n","        reader = csv.DictReader(dataset_fr, delimiter=delimiter)\n","        rows = []\n","        for row in reader:\n","            rows.append(row)\n","    return rows"],"metadata":{"id":"RhE4PB3goWf-","executionInfo":{"status":"ok","timestamp":1703221160292,"user_tz":300,"elapsed":138,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["nlp = spacy.load(\"en_core_web_md\")"],"metadata":{"id":"dH9b2UfKoZwq","executionInfo":{"status":"ok","timestamp":1703221163741,"user_tz":300,"elapsed":1723,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def parse_batch(texts):\n","    '''Tokenize and do POS taggging on a list of texts'''\n","    docs = list(nlp.pipe(texts))\n","    tokens_for_docs = []\n","    pos_tags_for_docs = []\n","    for doc in docs:\n","        tokens = [token.text for token in doc]\n","        pos_tags = [token.pos_ for token in doc]\n","        tokens_for_docs.append(tokens)\n","        pos_tags_for_docs.append(pos_tags)\n","    return tokens_for_docs, pos_tags_for_docs"],"metadata":{"id":"4NWLkio5odp_","executionInfo":{"status":"ok","timestamp":1703221165992,"user_tz":300,"elapsed":144,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["import pickle\n","d_vec_path_multi = '/content/Expanding-on-Lexical-Stylistic-Features-modified/data/complexity/dvecs/bert-base-multilingual-uncased_4_layeragg_seeds7_abtt_dvec.pkl'\n","with open(d_vec_path_multi, 'rb') as f:\n","    d_vec_multi = pickle.load(f)"],"metadata":{"id":"BkGZW7lpzhpf","executionInfo":{"status":"ok","timestamp":1703221260434,"user_tz":300,"elapsed":333,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["d_vec_multi"],"metadata":{"id":"C33dlF4a0L9d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703221263467,"user_tz":300,"elapsed":453,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"7258e7db-21bf-4840-ddf7-01aaee2c6960"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 7.4498e-02,  1.0696e-01, -4.7509e-02, -1.1646e-02,  2.7340e-01,\n","        -4.4638e-01, -1.3620e-01,  2.0809e-01,  7.8195e-03, -1.0114e-02,\n","        -6.4839e-01, -1.1850e-01,  1.3369e-02, -1.6499e-01, -3.7129e-01,\n","        -8.1940e-02,  2.9869e-01, -3.2252e-01, -4.6161e-01,  2.6546e-01,\n","         6.9535e-01, -2.1788e-01, -1.3974e-01, -1.4617e-01, -4.8997e-01,\n","        -1.5188e-01,  1.7437e-01, -2.2865e-01,  1.2962e-01,  4.4747e-02,\n","         1.8652e-01, -2.5785e-02,  4.4443e-01,  3.4890e-01,  2.6043e-01,\n","        -2.8135e-02, -4.4724e-01,  3.1727e-01,  5.3108e-02,  6.7207e-02,\n","         6.3194e-01,  3.1850e-01,  3.8691e-02,  3.5640e-01, -1.0124e-01,\n","        -1.7705e-01, -4.1254e-01,  2.0145e-01, -4.0681e-01, -2.6418e-01,\n","        -5.7051e-01,  1.2120e-01, -4.3955e-01,  4.2288e-02, -4.5738e-02,\n","        -1.1625e-01,  1.1219e-01, -1.7723e-02,  1.5880e-01, -1.5530e-01,\n","         5.0215e-01, -6.3538e-02,  2.0319e-01,  5.9803e-02,  2.4218e-01,\n","        -4.0764e-01, -2.6915e-02, -1.4946e-01,  3.8525e-01,  1.8208e-02,\n","         3.8155e-01, -1.6528e-01, -2.7976e-01,  1.7943e-01,  1.7872e-03,\n","         3.5474e-02, -3.2681e-01,  1.6183e-01,  7.9174e-02,  3.3801e-01,\n","         3.0571e-01, -4.0266e-02,  9.8110e-02, -1.7476e-01, -6.3307e-02,\n","         6.2744e-02, -1.6682e-01,  2.9431e-01, -4.1950e-01,  1.5748e-01,\n","        -2.0266e-01, -2.4993e-01,  1.3041e-01,  8.8065e-02, -3.4481e-01,\n","         9.7486e-02,  4.1393e-01, -1.6698e-02,  3.2959e-01,  1.9667e-01,\n","         1.9379e-01,  2.1547e-01, -3.3397e-01,  4.7643e-01, -1.5131e-01,\n","         1.3765e-01,  2.7909e-02,  5.6745e-02,  7.3971e-02, -4.7935e-01,\n","        -1.0651e-01,  2.9347e-01, -3.7524e-02,  7.6179e-02,  5.8262e-02,\n","         4.8147e-01,  1.8026e-01,  5.7607e-02, -1.0525e-01,  1.9814e-01,\n","        -2.6768e-01,  2.5221e-01, -3.6621e-02,  5.5379e-02,  8.5050e-02,\n","        -3.1419e-01, -2.6126e-01, -7.4342e-02, -2.3074e-01, -1.1757e-01,\n","         4.7478e-01, -4.4962e-02, -1.8353e-01, -2.1090e-01,  8.5920e-02,\n","         3.3132e-01, -1.1217e-01,  9.5952e-03,  2.2328e-01, -2.9967e-01,\n","         9.2660e-02,  3.3092e-01,  2.0732e-01, -1.3535e-01,  2.4777e-01,\n","        -4.5955e-01, -9.7271e-04, -1.2608e-01, -1.2831e-01, -3.4844e-01,\n","         2.4517e-01,  3.4569e-01, -3.1202e-01,  1.0568e-03,  1.3062e-02,\n","         1.0884e-01,  1.0353e-01, -3.1389e-01,  4.8753e-02,  4.3526e-02,\n","         4.7454e-02, -1.4042e-01, -3.3447e-01,  6.3142e-02, -2.1619e-01,\n","        -1.5460e-01,  2.0075e-01,  7.0938e-02, -2.9239e-01, -4.3950e-02,\n","         2.3373e-01, -3.1232e-01,  1.3707e-01, -2.9469e-01, -3.5272e-01,\n","        -9.3254e-02,  2.5764e-01,  7.2432e-02,  1.0474e-01, -1.1899e-01,\n","        -4.2198e-02, -5.1178e-01, -2.7886e-02,  8.8381e-02,  4.1972e-01,\n","        -1.3340e-01, -1.1880e-01,  1.5474e-02, -3.1328e-01, -1.5177e-01,\n","         1.9467e-01,  2.1993e-01,  7.9513e-01, -1.6199e-01, -3.3517e-01,\n","         2.0954e-01,  5.9853e-01,  3.2383e-01, -8.3557e-02, -1.1772e-01,\n","         2.6793e-02, -2.7015e-01,  1.4987e-01, -4.9022e-01, -3.0805e-01,\n","         3.3639e-01, -1.0888e-01, -7.5700e-02,  6.5065e-01,  1.4287e-01,\n","         6.9263e-02,  4.4761e-01,  3.7558e-02,  2.5669e-01, -4.8794e-02,\n","         7.7504e-02, -3.3594e-02,  2.2643e-01, -2.3753e-01, -2.2078e-01,\n","        -7.8828e-03,  5.0550e-02, -1.0141e-01,  9.4217e-02,  3.6762e-01,\n","        -2.4928e-01,  2.1379e-02, -9.8812e-02, -1.9278e-01,  4.1184e-02,\n","         5.4267e-01, -3.3618e-01, -2.6110e-01, -1.6534e-02,  2.2779e-01,\n","        -6.8561e-01,  1.4413e-02, -1.4434e-01,  1.9270e-04, -1.1216e-02,\n","        -1.1368e-01, -4.7916e-02, -8.4430e-02, -5.9483e-02,  1.8173e-02,\n","        -7.4386e-02,  2.0836e-01,  1.0682e-01,  2.5173e-02,  2.0121e-01,\n","         3.6787e-01, -2.7121e-01,  1.3912e-01,  5.8732e-01, -1.4843e-01,\n","         2.8578e-02, -3.4725e-01,  6.8862e-01, -2.8384e-01, -5.8231e-02,\n","        -2.7226e-01,  2.6085e-01,  3.6225e-01, -3.0146e-01, -9.5262e-01,\n","        -7.4362e-02, -2.8540e-01, -1.1809e-01, -7.7372e-02, -5.6216e-01,\n","         3.1890e-01,  2.5145e-01,  1.0236e-01,  1.3137e-01,  2.3247e-01,\n","         1.7935e-01, -7.6426e-02,  2.4569e-01, -5.7170e-02,  2.2305e-01,\n","         1.6196e-01,  1.5593e-01, -6.4648e-01,  2.6837e-01, -3.5252e-01,\n","         6.3777e-01,  2.2287e-01, -1.0139e-01, -5.9815e-01,  9.8506e-02,\n","         3.6862e-01, -1.5558e-01,  2.0096e-01,  1.6464e-01, -1.6438e-01,\n","        -5.1151e-02,  5.1940e-02, -1.7240e-01, -3.8838e-01, -3.3818e-02,\n","        -7.3840e-02,  2.8916e-02, -6.6931e-02, -5.3223e-02, -8.2690e-02,\n","        -2.3616e-01,  2.2780e-01, -2.4366e-01, -4.8687e-02, -2.0114e-01,\n","         1.9558e-02, -3.1097e-01, -1.7595e-01,  1.2666e-01,  4.8214e-01,\n","        -2.4773e-01,  7.8952e-02, -5.4979e-02, -8.8619e-02, -1.8741e-01,\n","         6.4930e-02,  3.6981e-01,  3.8470e-01,  8.3579e-03,  3.4114e-01,\n","         3.8419e-02, -4.9314e-01,  3.7864e-02, -4.6407e-01,  1.1973e-01,\n","         2.6440e-01,  2.9917e-01, -1.6279e-01, -5.3172e-02, -3.1930e-01,\n","        -7.6084e-03, -1.0715e-01, -1.7934e-02,  1.9817e-01,  1.0936e-01,\n","         1.9164e-01, -1.5295e-01, -6.2707e-01,  1.8980e-01,  2.0484e-01,\n","         7.2461e-02, -3.2831e-01,  3.1140e-01, -2.5949e-01,  7.4545e-02,\n","        -2.0024e-02,  4.3091e-01, -1.0776e-01,  8.3485e-02, -3.2732e-01,\n","         1.7412e-01,  2.6829e-01, -2.3476e-01,  1.5463e-01, -2.8263e-01,\n","         2.1664e-01,  2.5496e-01,  4.2698e-01,  3.6077e-01, -4.0233e-02,\n","         1.8764e-01,  1.5789e-01,  5.0715e-02, -1.5679e-01, -6.1052e-01,\n","         4.8996e-02, -4.2666e-02, -1.9933e-01, -1.9705e-01,  7.2754e-01,\n","         1.1406e-01,  1.6022e-01, -4.2126e-02, -2.7449e-01, -8.3668e-03,\n","        -2.0828e-01, -1.4287e-01, -1.2049e-03,  1.3445e-01, -5.0195e-01,\n","        -7.7384e-02,  7.7679e-02, -2.2318e-01, -1.1640e-02,  3.8088e-01,\n","         5.0007e-02, -1.8074e-01,  2.2861e-01,  3.4943e-01,  2.5713e-01,\n","         7.7743e-02, -1.4984e-01,  2.3075e-01,  4.1567e-01,  6.7870e-04,\n","         1.2144e-01,  2.5925e-01, -1.6961e-01,  1.7452e-01,  3.4588e-01,\n","        -3.5365e-01,  2.7556e-01,  1.0929e-01, -6.4458e-02, -4.6904e-02,\n","        -3.5353e-01, -1.8520e-02, -1.0018e-01,  2.2345e-01, -1.5625e-01,\n","        -3.4960e-01, -6.0330e-02, -1.0844e-02,  9.4813e-02, -1.6798e-02,\n","        -3.6593e-01, -8.5462e-02,  3.6444e-01,  6.8165e-02,  4.0266e-01,\n","        -4.2277e-02, -2.1843e-01,  9.4487e-02,  6.1997e-01, -8.3452e-02,\n","        -2.6498e-01, -4.2093e-01, -3.5905e-02, -3.8932e-01,  6.5324e-01,\n","         3.6852e-01, -2.8195e-01, -2.3299e-01,  4.7296e-01,  3.3428e-01,\n","         3.4607e-01,  1.7256e-01, -1.3411e-01,  1.4797e-01,  4.1097e-01,\n","         3.7802e-01,  3.8826e-01,  3.6215e-01, -1.7011e-01,  2.2869e-01,\n","        -1.4710e-01, -1.2639e-01,  3.5845e-02, -2.7984e-01, -2.9154e-01,\n","         1.3906e-01,  2.7710e-01, -2.5236e-01, -1.1128e-01, -7.3700e-01,\n","         1.8829e-01, -4.0270e-02, -4.0008e-01,  2.5477e-01, -2.6324e-01,\n","        -1.7689e-01,  4.4264e-01, -3.3578e-01,  3.1603e-01, -1.8588e-01,\n","        -4.3573e-01, -1.5018e-01,  1.1898e-01, -8.3671e-02,  1.9438e-01,\n","        -1.2775e-01, -1.0171e-01,  5.8119e-01,  4.0385e-02,  2.5982e-01,\n","         2.4555e-01, -1.9145e-01,  1.7654e-01, -2.9260e-01,  2.3129e-01,\n","         3.2904e-02,  3.4916e-01, -3.4347e-01, -3.2391e-01, -7.5008e-02,\n","        -2.3398e-01,  2.2239e-01, -1.5263e-01,  2.7556e-01,  2.9052e-01,\n","        -3.1622e-02, -9.4216e-02,  5.3231e-01, -2.9893e-01, -2.3175e-02,\n","         3.7803e-02, -4.2040e-01,  3.4774e-02,  4.6511e-01, -1.8929e-01,\n","        -2.5787e-01, -6.6443e-02,  3.1552e-01, -2.4751e-01,  3.6257e-01,\n","         7.8678e-02, -2.7694e-01,  1.7448e-01, -1.5555e-01,  1.3619e-01,\n","         2.4758e-01,  3.4087e-01,  4.3554e-01,  2.1595e-02,  2.0433e-01,\n","        -3.0768e-01,  6.1336e-02, -9.0177e-02, -3.8204e-01,  3.3859e-03,\n","        -5.3336e-01,  2.4577e-01, -7.0732e-03,  1.8081e-01,  2.7894e-01,\n","         1.1255e-01, -6.6872e-02,  3.2757e-01,  1.9578e-01, -2.3449e-02,\n","        -2.5897e-01,  7.2549e-01, -1.1396e-01,  3.4743e-01,  3.1762e-01,\n","         2.5688e-01,  3.4923e-02, -1.1532e-01,  1.7912e-01,  3.9140e-02,\n","         1.3085e-01, -9.6184e-02,  1.0462e-01,  3.2275e-01,  1.7639e-01,\n","         3.1957e-01,  6.3849e-02,  3.8845e-01, -4.5770e-02,  2.8226e-02,\n","         5.6350e-01, -1.5085e-01,  2.0768e-01, -9.6516e-02,  1.4654e-01,\n","         1.5405e-01, -4.0216e-01, -2.4929e-02, -5.3581e-01, -7.9796e-02,\n","        -5.2202e-01, -3.4229e-01,  1.1648e-01, -4.3672e-01,  1.7557e-01,\n","        -3.2006e-01,  1.1655e-02, -1.6068e-01, -1.8349e-01,  4.0656e-01,\n","        -2.9387e-01, -3.5548e-02,  3.0481e-01,  2.4419e-01, -5.0992e-02,\n","        -4.4290e-01,  4.4356e-02,  4.2364e-01, -1.0818e-02,  1.0327e-01,\n","        -4.6908e-02,  2.0523e-01, -1.4425e-01,  1.8533e-01,  4.8534e-01,\n","         2.2756e-01, -5.3443e-01, -4.0317e-01, -3.2274e-01, -1.6948e-02,\n","         5.0264e-02,  3.7801e-01, -2.3936e-01,  4.7399e-02, -1.2061e-01,\n","         1.2201e-01,  2.5023e-01, -1.4610e-01,  2.1970e-01, -3.9758e-01,\n","        -5.2179e-02, -4.1784e-01, -1.2719e-01, -1.4136e-01, -1.3356e-01,\n","        -1.8344e-01,  1.9393e-01,  4.0812e-01,  5.6098e-02, -2.0041e-01,\n","        -4.2690e-01,  2.7936e-01, -8.4410e-03,  8.9502e-02, -2.0977e-01,\n","        -3.4864e-01, -2.5515e-02, -3.2548e-01, -1.5154e-01,  1.6002e-01,\n","         1.9584e-01, -4.6907e-01, -2.6859e-01,  3.2029e-01, -3.7582e-01,\n","         2.4652e-01, -9.3937e-02,  2.7438e-02, -1.6278e-01,  1.7782e-01,\n","        -7.0407e-02,  1.7009e-01, -3.7605e-01, -1.9072e-01,  1.4035e-01,\n","        -7.5805e-02,  3.8358e-02,  1.1799e-01, -1.5619e-02, -1.7547e-01,\n","        -1.1326e-01, -5.7485e-01, -4.6557e-01,  4.2779e-01, -3.2039e-01,\n","         1.3684e-01, -1.2201e-01,  5.1446e-02, -1.0998e-01,  7.9602e-02,\n","         2.2993e-02,  1.1661e-01, -3.1695e-01,  1.0296e-01, -1.9728e-01,\n","         8.9529e-02, -2.1928e-01, -4.5422e-01, -5.9522e-02,  4.4506e-01,\n","         3.7509e-01,  1.3862e-01, -1.5652e-01,  1.0811e-01, -4.3240e-02,\n","        -2.5290e-02,  8.3077e-02, -2.0221e-01,  3.8765e-03, -4.5329e-01,\n","         3.2262e-01, -9.6589e-02, -1.1405e-02, -2.5708e-01, -6.9025e-02,\n","         3.9045e-01, -5.9756e-02,  7.8711e-02,  6.0174e-02,  9.3903e-02,\n","        -4.4205e-01, -1.7862e-01,  3.9924e-02, -3.8742e-01, -2.6437e-01,\n","        -1.1197e-01, -2.2882e-01, -2.4711e-01,  3.1719e-01, -7.2658e-02,\n","        -1.4652e-01,  3.3911e-02,  1.7801e-01, -1.9504e-01, -2.5769e-01,\n","         7.3966e-02,  1.8406e-01,  1.4208e-01, -3.0206e-02,  5.3483e-01,\n","        -1.3185e-01,  4.2387e-01, -1.3015e-01,  9.0548e-02,  7.3798e-02,\n","         1.4013e-01, -4.3556e-01, -9.8889e-02, -1.0502e-01, -2.1352e-01,\n","        -6.5296e-01, -3.2036e-01,  3.7091e-01, -4.5556e-02,  7.7029e-01,\n","        -8.5175e-01,  3.6534e-01,  1.2846e-01, -1.1399e-01,  4.2385e-01,\n","         1.9492e-02,  2.1047e-01,  1.5970e-01,  6.2134e-02,  5.7864e-01,\n","        -1.3455e-01,  6.9711e-02, -4.6182e-01, -2.8242e-01, -2.1761e-02,\n","        -2.1090e-01,  1.8808e-01, -4.0552e-01,  4.3843e-01, -4.3713e-01,\n","         1.6322e-01,  3.5039e-01, -4.3052e-03, -2.6335e-01, -1.6320e-01,\n","        -3.2228e-01, -1.1278e-01,  2.8937e-01, -1.4603e-01, -4.2709e-01,\n","         2.4029e-01, -3.0726e-01, -1.6533e-01, -1.9945e-03,  1.0178e-01,\n","        -8.8908e-02, -5.0516e-01, -3.4392e-01, -5.8282e-01,  7.3982e-02,\n","         2.7082e-01, -1.0781e-01,  9.2977e-02, -1.7826e-01, -2.7805e-01,\n","        -1.6795e-01,  3.5665e-01, -1.4969e-01], device='cuda:0')"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["import pickle\n","d_vec_path_multi_iso = '/content/Expanding-on-Lexical-Stylistic-Features-modified/data/complexity/dvecs/bert-base-multilingual-uncased_4_layeragg_seeds7_abtt_isovec.pkl'\n","with open(d_vec_path_multi_iso, 'rb') as f:\n","    isovec_multi = pickle.load(f)"],"metadata":{"id":"UFnlXSDT3atF","executionInfo":{"status":"ok","timestamp":1703221271440,"user_tz":300,"elapsed":159,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["isovec_multi"],"metadata":{"id":"tAokFuOn3uH-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703221272948,"user_tz":300,"elapsed":167,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"0363390e-a475-46ff-d823-185f13f91d46"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'complexity': {'mean': tensor([-3.7744e-01,  5.9435e-01,  4.1583e-02,  2.0695e-01,  7.5354e-02,\n","           3.7773e-01,  1.3657e-01,  4.1837e-01, -3.7890e-01,  6.5957e-02,\n","          -6.4801e-02, -8.5744e-01, -6.5258e-01,  2.7256e-01, -1.7190e-01,\n","          -5.7513e-02, -1.9299e-01, -3.3583e-01, -1.8349e-01,  2.6807e-02,\n","           2.0003e-01, -1.5620e-01,  1.1244e-01, -6.9703e-02,  1.3413e-01,\n","          -5.6311e-01, -1.2310e-01, -2.0870e-02,  3.2147e-01,  3.1695e-01,\n","          -4.8895e-02,  2.0364e-01, -2.4029e-01, -1.3647e-01, -2.2425e-01,\n","          -1.1123e-01,  1.6652e-01,  1.0136e-01, -3.3512e-02, -3.9666e-01,\n","          -4.2530e-01, -5.6892e-02,  4.5444e-01,  3.1838e-03,  2.6777e-01,\n","          -6.1383e-01,  3.1213e-01, -1.4799e-01,  2.8694e-01,  1.3584e-01,\n","          -3.0638e-01,  4.6757e-02,  3.2281e-01,  1.8066e-01, -2.5394e-02,\n","          -2.8089e-01,  4.0781e-02, -9.9219e-03, -1.7850e-01, -3.6180e-02,\n","          -3.2053e-01, -2.1758e-01,  1.5340e-01,  9.4980e-02,  2.4475e-01,\n","           2.3766e-01, -2.0405e-01,  1.6050e-01, -1.0693e-01, -6.6189e-02,\n","           8.3302e-02, -9.2623e-02,  3.4252e-01,  1.8724e-01,  1.0743e-01,\n","          -4.5340e-02, -1.4255e-02, -3.5553e-01, -2.6634e-01,  3.5036e-01,\n","          -1.1921e-01,  7.5908e-02, -3.3114e-01,  7.5139e-01,  1.5051e-01,\n","           6.5609e-02, -3.5070e-01, -1.2180e-01,  9.1026e-02,  1.2094e-01,\n","          -3.6028e-01,  2.6850e-01, -1.9947e-01,  2.5484e-01,  4.5985e-03,\n","          -2.0658e-01, -6.1405e-01, -9.3767e-02,  2.2641e-01, -2.6360e-01,\n","           2.0645e-01,  3.4590e-01, -2.6158e-01, -7.2457e-02, -1.2582e-01,\n","          -8.2056e-02, -1.9544e-01,  1.5007e-01, -4.4265e-01,  1.2083e-01,\n","           2.1735e-01,  6.3944e-01, -2.1434e-01,  2.0051e-01, -6.4085e-01,\n","          -4.3225e-01, -4.8836e-01, -5.5344e-01,  1.9638e-01,  5.6895e-02,\n","          -2.8343e-01, -4.1999e-01, -3.2407e-01,  2.3639e-01, -4.7709e-01,\n","           2.6468e-01,  4.0566e-01,  3.3073e-01, -4.3820e-02, -2.6466e-02,\n","          -1.0133e-01,  1.1685e-01,  3.6905e-03,  2.3423e-01, -2.4977e-01,\n","          -2.4705e-01, -1.9371e-01,  3.1096e-01, -1.5946e-01,  3.3098e-01,\n","          -7.2189e-02, -1.2742e+00,  4.4913e-02, -1.9802e-01, -4.1151e-02,\n","          -8.1223e-02, -4.8568e-01,  5.1987e-01,  6.1987e-03, -2.6605e-01,\n","          -1.4167e-01, -1.9686e-01,  4.8134e-02, -1.8806e-01,  2.1712e-01,\n","          -2.3284e-01, -4.6594e-01, -1.1749e-01, -5.3164e-02, -7.9837e+00,\n","          -4.3359e-02,  4.0051e-02, -1.4131e-01, -8.7755e-02,  1.4283e-01,\n","           5.6379e-01,  9.1887e-04,  3.7562e-02, -5.3134e-02,  1.6820e-01,\n","          -6.0881e-02, -9.6195e-02, -1.0666e-01,  9.0655e-02,  5.5221e-02,\n","           1.9658e-01,  5.8383e-01, -3.5932e-01,  2.4404e-02, -3.8896e-01,\n","          -3.9870e-01, -8.9930e-02, -2.2242e-01,  3.7908e-02, -1.3383e-01,\n","           4.6549e-01, -5.5005e-02,  2.2521e-01,  1.8953e-01, -8.2046e-02,\n","           3.4658e-01, -1.2636e-01, -2.2145e-01,  1.1241e-01,  6.9034e-02,\n","          -1.5059e-01, -1.3045e-01,  1.2019e-01, -1.6812e-01,  7.3614e-02,\n","           3.1851e-02, -2.1032e-02,  4.8030e-01,  3.7506e-01,  2.3535e-02,\n","           1.4826e-02,  8.9662e-02,  3.4392e-01,  1.0344e-01, -2.4631e-01,\n","           9.9712e-01, -1.4667e-01, -1.2211e-01, -3.6220e-01,  4.8525e-01,\n","          -4.5008e-01,  1.0033e-01,  1.7090e-01, -1.4134e-01,  5.3568e-01,\n","          -4.6777e-01, -2.0884e-01,  4.1674e-02, -3.9456e-01,  1.3804e-02,\n","           6.1276e-01, -2.2839e-01, -3.2364e-01, -4.0426e-01,  4.2664e-01,\n","          -1.3852e-01, -2.8397e-02,  5.0266e-02,  2.1088e-01,  7.2591e-01,\n","           2.7302e-01,  1.8428e-02, -2.2213e-01, -6.3941e-02,  5.4306e-02,\n","          -3.6543e-01,  2.8204e-01, -1.0366e-01,  4.0027e-01,  5.9007e-01,\n","           6.6407e-01,  1.9070e-01,  3.2236e-01,  4.1208e-01, -1.7781e-01,\n","          -2.9354e-01,  2.1720e-01,  2.0224e-01, -2.7463e-01,  1.1479e-01,\n","          -1.6962e-01,  1.9699e-01,  8.5349e-03, -3.0805e-02, -4.2520e-01,\n","          -1.0254e-01, -1.2131e-01,  7.2202e-02, -5.7088e-04, -6.8077e-02,\n","          -8.8545e-02,  2.0349e-02,  1.7144e-01, -6.2229e-02, -6.6715e-02,\n","          -6.6969e-02, -2.8695e-01, -4.3462e-01, -7.8222e-02, -4.2303e-01,\n","           1.1599e-01,  2.1077e-01, -2.0735e-01,  2.8850e-01, -2.3026e-01,\n","          -1.6932e-01,  8.4017e-01,  7.1178e-01,  1.4287e-01,  4.2926e-02,\n","           4.9316e-02,  3.0628e-01,  2.4858e-01,  4.7911e-01, -2.4068e-01,\n","          -3.5846e-01, -2.1417e-02, -2.5960e-02, -2.1620e-03,  8.4114e-01,\n","           2.9702e-01,  9.8404e-02, -2.2305e-02,  1.7868e-02,  2.4447e-02,\n","          -1.5836e-01, -1.9270e-01,  1.2622e-01, -6.1386e-02, -2.6416e-01,\n","           2.8811e-01,  2.8842e-02, -2.1973e-02, -1.9080e-01,  1.1149e-01,\n","           3.4010e-01,  1.3558e-03, -3.5812e-02,  1.8997e-01, -3.6969e-02,\n","           1.6843e-01,  4.7523e-02,  5.7354e-01,  1.1880e-01,  7.9321e-01,\n","           5.5473e-02, -1.6610e-01, -1.3488e-01,  1.5513e-01, -2.8353e-02,\n","           1.4652e-02,  4.0201e-02,  3.6946e-02,  3.6637e-01, -8.0931e-01,\n","           3.1228e-01, -1.0123e-01, -4.1580e-02, -1.6525e-01, -1.6142e-01,\n","           1.3555e-01, -3.1097e-02,  1.5217e-01,  7.3342e-02, -3.8510e-01,\n","          -1.6689e-01, -1.4419e-01,  5.2310e-01, -6.9442e-01, -1.7032e-01,\n","          -1.9340e-01,  7.1221e-02,  3.5332e-01,  1.2736e-01, -4.1406e-01,\n","           1.7123e-01,  2.1262e-01,  5.4288e-01, -4.7402e-01,  3.8847e-01,\n","          -3.6969e-02, -4.9004e-01, -6.1319e-02, -3.6608e-01,  2.9093e-02,\n","           2.1566e-03,  4.4003e-02, -2.9587e-01, -2.8968e-01, -9.0099e-02,\n","          -5.4303e-01,  2.2958e-01,  8.7010e-02, -5.7912e-02,  2.9014e-01,\n","          -1.4918e-01,  5.8268e-02, -2.1397e-01, -2.8009e-01, -5.8535e-01,\n","           3.3667e-01, -2.2229e-01, -2.8660e-01, -1.7856e-02,  2.7316e-01,\n","          -2.2865e-02,  3.8429e-01,  2.0697e-01,  4.0158e-01,  7.1261e-02,\n","           9.0704e-02, -5.7463e-01,  3.0749e-01, -1.1124e-02, -1.0215e-02,\n","           3.4476e-01, -3.2345e-02,  1.7033e-02, -2.0496e-01,  5.1366e-02,\n","           1.5524e-01, -8.2385e-02, -3.8423e-02, -1.6404e-01, -5.9049e-02,\n","          -1.4669e-01,  1.8093e-01, -2.5495e-01, -2.2632e-01,  6.8963e-02,\n","           1.9396e-01,  7.4461e-02,  4.0357e-02,  2.5365e-01, -5.9676e-01,\n","          -2.2852e-01, -6.6430e-03,  6.3976e-01, -4.1531e-01,  7.2379e-02,\n","          -1.8554e-01,  2.2255e-01,  9.1955e-02,  5.1811e-01,  1.5347e-01,\n","          -4.5538e-01, -1.4960e-01, -7.4040e-01,  1.5404e-01, -6.9602e-03,\n","          -3.4977e-01, -2.7443e-01,  6.5890e-04, -2.5464e-02,  2.0730e-01,\n","          -3.1639e-01,  1.9939e-01,  8.7374e-03,  5.1586e-01, -5.9511e-01,\n","           5.2587e-02,  3.0110e-02,  1.9833e-01,  3.2903e-01, -5.5174e-02,\n","          -1.3985e-01,  2.3955e-01, -1.2933e-02, -2.2267e-01,  1.4210e-02,\n","           3.7106e-01,  5.2160e-01, -7.0929e-02,  2.9620e-04,  3.0228e-01,\n","           1.9994e-01, -2.7081e-01, -1.0942e-01, -2.3876e-01,  1.8802e-01,\n","           2.7504e-01, -2.2050e-01, -5.6494e-02, -9.5274e-02,  5.9866e-01,\n","          -1.4607e-01,  3.3882e-01, -9.0100e-02, -1.0991e-01, -2.5984e-01,\n","           2.0771e-01,  2.5274e-01,  3.4224e-01, -3.2785e-01, -1.6528e-01,\n","          -1.7987e-01,  4.7210e-02, -8.6119e-02, -5.2315e-02,  2.0144e-01,\n","          -1.9262e-01, -3.8854e-02,  5.3377e-02, -8.4224e-02,  1.0891e-02,\n","          -6.2280e-01, -4.3684e-02,  3.7731e-01, -2.4318e-01,  2.9489e-02,\n","          -4.7055e-01, -1.1985e-01,  1.5188e-01, -4.5838e-03,  3.1660e-02,\n","          -7.7782e-02, -1.5803e-01,  4.6429e-02, -4.8502e-01, -1.0919e-01,\n","           5.0833e-01,  1.2565e-01, -3.6534e-02,  4.1034e-02,  9.7719e-02,\n","          -1.7646e-01, -1.1826e-01,  6.0768e-02, -4.3003e-02,  1.8166e-01,\n","           6.7983e-03, -1.0469e-01, -9.3943e-01,  1.0268e-01,  2.1211e-01,\n","          -3.4345e-01,  4.8086e-01, -5.8573e-01,  3.4681e-01, -2.5225e-01,\n","           1.2983e-01, -2.8639e-02, -3.8927e-01, -3.9468e-01,  2.5848e-01,\n","           1.0832e-01,  1.6154e-01,  8.7059e-02,  5.6198e-02,  5.6526e-01,\n","           5.3712e-02, -4.8966e-02,  6.8485e-02, -2.6225e-03,  1.1968e-01,\n","          -9.9193e-02,  3.4687e-02, -4.6512e-01, -2.5780e-01, -4.4126e-02,\n","           4.0051e-01, -1.6309e-01,  4.0430e-01,  4.8277e-01,  3.0459e-02,\n","          -9.4265e-02, -1.9046e-01, -4.1622e-01,  2.1524e-01,  4.3703e-01,\n","          -2.8521e-01, -3.1686e-01, -4.3622e-02, -4.2425e-01, -6.0531e-01,\n","          -1.8414e-01, -2.5814e-01, -2.0982e-01, -5.7504e-01,  4.7937e-01,\n","          -2.6988e-01, -3.3000e-01,  1.9727e-01,  1.2756e-01, -5.8725e-01,\n","          -8.1047e-02,  1.8138e-01,  7.5747e-02, -2.2612e-01, -3.0149e-01,\n","          -3.1614e-02,  3.0669e-01, -1.1232e-01,  4.5041e-01, -4.0436e-01,\n","          -1.3557e-01, -2.0471e-02, -2.8424e-01,  5.6637e-02,  6.7460e-02,\n","          -2.0526e-01,  1.2323e-01,  1.9435e-01,  1.3187e-01, -4.0936e-02,\n","           7.5102e-02, -2.6688e-01, -2.4773e-02,  5.2688e-02,  1.7961e-01,\n","           9.5259e-02, -2.0913e-01, -1.0421e-01, -2.2949e-01, -9.2884e-02,\n","           1.4227e-01,  2.1486e-01,  3.8600e-02, -5.3927e-02, -5.0205e-01,\n","           9.4097e-02,  8.0602e-02,  1.5868e-01,  2.9753e-01, -1.2490e-01,\n","          -5.6231e-02, -3.9194e-01,  2.6338e-01,  3.6460e-01, -2.1958e-01,\n","           2.0625e-01,  3.8779e-01,  3.4759e-01,  6.1081e-02, -1.5796e-02,\n","          -4.3195e-01,  2.6103e-02, -3.1192e-02,  8.6685e-01,  1.5435e-01,\n","          -2.2790e-02, -1.3502e-01, -8.8927e-04, -1.8745e-01, -1.2822e-01,\n","           2.0476e-01,  2.5547e-01,  3.9321e-01,  1.0328e-01,  1.4475e-01,\n","          -6.3358e-02,  1.2456e-01,  1.1822e-01,  1.7526e-01,  9.2992e-02,\n","          -2.8239e-01,  4.6909e-01, -5.6327e-02,  4.9406e-02,  5.7869e-02,\n","           1.3104e-01,  1.7352e-01,  4.7811e-01, -3.3809e-01, -3.5337e-02,\n","           3.3381e-01,  2.0491e-01, -2.1527e-02,  1.5963e-01, -1.7324e-01,\n","           2.0260e-01,  2.9344e-01,  3.6522e-02, -1.1040e-01,  1.0019e-01,\n","           3.0198e-01,  2.7185e-01, -5.9847e-02,  3.3077e-02,  6.3409e-01,\n","          -3.2184e-01, -3.1348e-02,  3.3051e-01, -2.4340e-01,  1.3706e-01,\n","           4.0890e-01,  1.5046e-02,  3.4427e-01, -3.6993e-01,  2.1075e-01,\n","          -3.8470e-01,  1.2817e-01,  1.7872e-01, -3.1202e-01,  1.1283e-01,\n","           3.9589e-01, -3.2960e-02, -4.0337e-01, -5.0454e-01,  4.3002e-01,\n","          -3.6319e-01, -3.7200e-01,  2.7256e-01, -5.8905e-02,  8.1136e-02,\n","          -4.4951e-01, -1.3860e-01, -4.8960e-01, -4.4598e-02, -3.6880e-01,\n","           2.3627e-01, -3.1471e-01,  1.1375e-01,  2.2499e-01, -2.0665e-01,\n","           2.8702e-01, -6.4574e-02,  2.6018e-01, -2.0846e-01,  1.6945e-01,\n","           2.6203e-01, -1.0259e-01,  2.4650e-01, -1.3872e-01,  6.0778e-02,\n","          -1.0570e-01, -4.2651e-01,  1.0334e-01,  2.5987e-02,  1.9516e-01,\n","           8.5849e-02, -3.2251e-01, -1.0592e-01,  1.0755e-01,  4.5836e-01,\n","          -2.6860e-01, -2.9842e-01, -3.5076e-01, -3.1518e-01, -2.8435e-01,\n","           2.8915e-01,  1.5047e-01, -2.1418e-01,  2.8596e-01, -3.1679e-01,\n","           3.9406e-01,  1.6863e-01,  4.0445e-01,  2.8132e-01, -6.2119e-01,\n","          -1.5180e-01,  8.7977e-02, -1.4551e-02,  1.3322e-01, -1.4089e-01,\n","          -2.3245e-02, -6.1007e-02, -1.6205e-01,  5.2034e-01, -3.5991e-01,\n","          -7.5438e-02,  6.3312e-01,  1.0233e-01, -3.8020e-01,  3.5350e-01,\n","          -9.3925e-02, -3.2692e-01,  6.0911e-01,  4.7816e-03, -1.3863e-01,\n","           2.2967e-01,  4.9733e-01, -1.7175e-01,  1.3985e-01,  3.8350e-01,\n","           3.4582e-03, -2.2342e-01, -1.9631e-01, -2.2868e-01, -2.6516e-01,\n","          -1.9983e-01, -3.6405e-01,  1.4201e+00,  1.7589e-01, -6.2781e-02,\n","          -1.3484e-02, -9.6386e-02, -2.2244e-01, -3.5582e-02,  2.7274e-01,\n","           6.6105e-02, -4.2153e-01, -2.4731e-01], device='cuda:0'),\n","  'std': tensor([0.3169, 0.4832, 0.2476, 0.2802, 0.4494, 0.4566, 0.4475, 0.3123, 0.4736,\n","          0.4276, 0.4724, 0.5273, 0.4321, 0.4675, 0.5223, 0.4738, 0.4523, 0.5276,\n","          0.5109, 0.4478, 0.5051, 0.4494, 0.5067, 0.4100, 0.4159, 0.4817, 0.4376,\n","          0.4992, 0.3030, 0.2674, 0.3752, 0.2549, 0.4971, 0.3568, 0.5006, 0.3092,\n","          0.4557, 0.4478, 0.4077, 0.3835, 0.5127, 0.5155, 0.4687, 0.4973, 0.4833,\n","          0.4474, 0.5774, 0.4848, 0.4821, 0.5070, 0.4610, 0.4128, 0.4977, 0.4671,\n","          0.4441, 0.3841, 0.4600, 0.4115, 0.3776, 0.4632, 0.4667, 0.4088, 0.5007,\n","          0.5113, 0.5017, 0.5109, 0.4401, 0.4858, 0.4287, 0.4440, 0.4752, 0.5090,\n","          0.5016, 0.5046, 0.4713, 0.4745, 0.4590, 0.4515, 0.5060, 0.4427, 0.4148,\n","          0.4484, 0.3777, 0.4021, 0.5232, 0.4298, 0.4714, 0.5437, 0.4539, 0.4623,\n","          0.4152, 0.4944, 0.5196, 0.4943, 0.4839, 0.4490, 0.4588, 0.5046, 0.4741,\n","          0.4290, 0.4784, 0.4426, 0.4894, 0.4853, 0.4210, 0.4590, 0.5178, 0.4326,\n","          0.3205, 0.4543, 0.5175, 0.4799, 0.4533, 0.4480, 0.4947, 0.4672, 0.4975,\n","          0.5243, 0.4584, 0.4522, 0.4866, 0.5076, 0.5033, 0.4477, 0.4460, 0.5162,\n","          0.2636, 0.3314, 0.4664, 0.5530, 0.4260, 0.4630, 0.5082, 0.4772, 0.4630,\n","          0.4809, 0.4752, 0.4101, 0.5884, 0.4808, 0.2274, 0.5366, 0.4226, 0.2033,\n","          0.4297, 0.3926, 0.4613, 0.5110, 0.4373, 0.4735, 0.4259, 0.2291, 0.4526,\n","          0.4140, 0.4850, 0.5264, 0.4397, 0.5290, 0.4012, 0.5978, 0.4549, 0.4607,\n","          0.4692, 0.4207, 0.4120, 0.4630, 0.4836, 0.5395, 0.3899, 0.3826, 0.2493,\n","          0.5030, 0.4414, 0.4710, 0.4727, 0.4507, 0.5232, 0.4572, 0.4761, 0.4333,\n","          0.5040, 0.5238, 0.4663, 0.4860, 0.4733, 0.4981, 0.5056, 0.4247, 0.4540,\n","          0.5071, 0.4324, 0.5183, 0.4573, 0.4783, 0.4694, 0.3590, 0.4065, 0.4818,\n","          0.4285, 0.4530, 0.4426, 0.4893, 0.4669, 0.4942, 0.5054, 0.4838, 0.5120,\n","          0.4304, 0.4586, 0.4588, 0.2046, 0.4759, 0.4832, 0.4425, 0.4900, 0.4498,\n","          0.4572, 0.4060, 0.4086, 0.3554, 0.2998, 0.4409, 0.4944, 0.4960, 0.5116,\n","          0.2009, 0.4645, 0.5105, 0.4638, 0.4701, 0.4426, 0.4249, 0.4097, 0.2526,\n","          0.3368, 0.4390, 0.4346, 0.3908, 0.4208, 0.4596, 0.4317, 0.3734, 0.4485,\n","          0.4137, 0.3114, 0.4457, 0.4586, 0.4511, 0.3708, 0.4489, 0.4140, 0.4314,\n","          0.4298, 0.4755, 0.4599, 0.4833, 0.3031, 0.4517, 0.4575, 0.5490, 0.4765,\n","          0.3721, 0.4620, 0.4510, 0.5182, 0.4196, 0.4457, 0.3928, 0.4837, 0.5233,\n","          0.4763, 0.4855, 0.4961, 0.4863, 0.3596, 0.5028, 0.4832, 0.4432, 0.3313,\n","          0.4299, 0.4657, 0.3574, 0.4528, 0.5227, 0.5375, 0.4721, 0.3875, 0.4300,\n","          0.4633, 0.4479, 0.4681, 0.4009, 0.4409, 0.3738, 0.4076, 0.4075, 0.4757,\n","          0.4166, 0.4323, 0.4309, 0.4822, 0.4974, 0.4340, 0.4259, 0.4573, 0.4889,\n","          0.5068, 0.4274, 0.5064, 0.3739, 0.4636, 0.4463, 0.4561, 0.3488, 0.5047,\n","          0.5022, 0.4286, 0.4966, 0.3694, 0.4861, 0.3406, 0.4949, 0.4458, 0.3310,\n","          0.4801, 0.4795, 0.5307, 0.2551, 0.4554, 0.2417, 0.3938, 0.4176, 0.4393,\n","          0.4409, 0.2263, 0.4282, 0.5351, 0.5589, 0.4448, 0.5198, 0.4316, 0.4866,\n","          0.5425, 0.4110, 0.4541, 0.4900, 0.5268, 0.3299, 0.4642, 0.4378, 0.4750,\n","          0.5254, 0.4691, 0.4938, 0.4544, 0.3500, 0.4656, 0.4699, 0.4865, 0.5086,\n","          0.4616, 0.4458, 0.4362, 0.4953, 0.4785, 0.3589, 0.4789, 0.2707, 0.4482,\n","          0.4416, 0.4321, 0.4373, 0.5042, 0.4810, 0.4022, 0.3386, 0.4687, 0.3378,\n","          0.4756, 0.4689, 0.4225, 0.4375, 0.4043, 0.4432, 0.4968, 0.4173, 0.4938,\n","          0.5158, 0.4768, 0.4723, 0.4407, 0.4737, 0.3209, 0.4834, 0.4636, 0.4865,\n","          0.4628, 0.5312, 0.5012, 0.4976, 0.4320, 0.4987, 0.4443, 0.4221, 0.3758,\n","          0.5437, 0.4735, 0.4761, 0.5262, 0.5228, 0.5131, 0.4818, 0.4794, 0.3504,\n","          0.3730, 0.4354, 0.4627, 0.3991, 0.3018, 0.4446, 0.4118, 0.4607, 0.4355,\n","          0.4640, 0.4840, 0.5090, 0.5214, 0.4515, 0.4932, 0.3983, 0.4998, 0.4561,\n","          0.4725, 0.3517, 0.5046, 0.4771, 0.4674, 0.4489, 0.4556, 0.4584, 0.3784,\n","          0.4673, 0.4987, 0.4828, 0.3212, 0.4758, 0.4822, 0.4853, 0.5173, 0.4694,\n","          0.5154, 0.2993, 0.4433, 0.5034, 0.5049, 0.5036, 0.4754, 0.5098, 0.4973,\n","          0.5050, 0.4488, 0.4942, 0.4566, 0.2648, 0.5205, 0.2794, 0.4868, 0.4781,\n","          0.4607, 0.4865, 0.5117, 0.4942, 0.4984, 0.4499, 0.4753, 0.5473, 0.5108,\n","          0.5317, 0.4275, 0.4159, 0.2983, 0.4585, 0.4414, 0.4424, 0.4933, 0.4408,\n","          0.4585, 0.4613, 0.5108, 0.4597, 0.4934, 0.4852, 0.4538, 0.4859, 0.4578,\n","          0.5145, 0.4539, 0.4864, 0.4399, 0.5011, 0.4474, 0.5029, 0.5130, 0.5186,\n","          0.4452, 0.4677, 0.3725, 0.4544, 0.5393, 0.4952, 0.3223, 0.5327, 0.3694,\n","          0.4709, 0.4197, 0.4297, 0.4867, 0.3784, 0.4641, 0.5210, 0.4737, 0.4178,\n","          0.4501, 0.5089, 0.3981, 0.4990, 0.4828, 0.5346, 0.3337, 0.4130, 0.2555,\n","          0.4533, 0.5675, 0.4890, 0.5124, 0.4245, 0.5335, 0.3801, 0.4655, 0.2902,\n","          0.4235, 0.4583, 0.3120, 0.4518, 0.4933, 0.5584, 0.4728, 0.2984, 0.4414,\n","          0.3483, 0.4737, 0.3118, 0.5317, 0.4776, 0.4733, 0.4946, 0.5117, 0.2518,\n","          0.4287, 0.5202, 0.4634, 0.4865, 0.4682, 0.5387, 0.5166, 0.4861, 0.4817,\n","          0.5096, 0.4766, 0.4151, 0.4334, 0.4980, 0.4481, 0.4863, 0.5104, 0.4731,\n","          0.2248, 0.4777, 0.3650, 0.3349, 0.4725, 0.4776, 0.4169, 0.4914, 0.4523,\n","          0.4928, 0.4974, 0.4745, 0.4335, 0.5189, 0.4910, 0.4576, 0.3908, 0.4703,\n","          0.5312, 0.3786, 0.5166, 0.5016, 0.4709, 0.5262, 0.5254, 0.4454, 0.5412,\n","          0.2691, 0.4058, 0.4276, 0.4244, 0.4376, 0.4675, 0.4433, 0.5466, 0.3834,\n","          0.5351, 0.4996, 0.4408, 0.4471, 0.5034, 0.4439, 0.4213, 0.4831, 0.3738,\n","          0.5128, 0.4590, 0.4951, 0.4405, 0.5162, 0.5181, 0.5545, 0.4553, 0.4490,\n","          0.4663, 0.4598, 0.5060, 0.4583, 0.5006, 0.4893, 0.4921, 0.4932, 0.4899,\n","          0.5032, 0.4427, 0.4421, 0.5217, 0.4668, 0.4940, 0.3955, 0.4401, 0.3541,\n","          0.3917, 0.4930, 0.4842, 0.2248, 0.4529, 0.4585, 0.3982, 0.4283, 0.4520,\n","          0.5028, 0.3654, 0.4711, 0.5030, 0.4949, 0.4028, 0.2357, 0.4249, 0.5268,\n","          0.2723, 0.4528, 0.4921, 0.4396, 0.4877, 0.4552, 0.4180, 0.5344, 0.4243,\n","          0.4892, 0.4559, 0.4124, 0.4765, 0.4680, 0.4924, 0.4639, 0.3593, 0.3044,\n","          0.3962, 0.4579, 0.4539, 0.4869, 0.4487, 0.4975, 0.5172, 0.4396, 0.2960,\n","          0.5340, 0.5077, 0.4135, 0.4485, 0.4880, 0.4868, 0.4642, 0.5191, 0.4445,\n","          0.4367, 0.4631, 0.4289, 0.4309, 0.4548, 0.4289, 0.4627, 0.4292, 0.4652,\n","          0.4930, 0.4882, 0.4905, 0.4735, 0.4896, 0.4413, 0.5799, 0.3630, 0.3579,\n","          0.5175, 0.4851, 0.3890, 0.4840, 0.3107, 0.4081, 0.2938, 0.4630, 0.4201,\n","          0.4285, 0.5093, 0.5070, 0.4901, 0.5162, 0.4657, 0.5246, 0.4204, 0.5011,\n","          0.5269, 0.5194, 0.4837, 0.2744, 0.3040, 0.4816, 0.4994, 0.3846, 0.4034,\n","          0.5058, 0.4589, 0.4749, 0.5096, 0.5402, 0.4824, 0.4339, 0.1320, 0.4309,\n","          0.4518, 0.3451, 0.4526, 0.4792, 0.3502, 0.4133, 0.2943, 0.5060, 0.4857,\n","          0.4826, 0.4237, 0.4808], device='cuda:0'),\n","  'pcs': tensor([[ 0.0519,  0.0793,  0.0374,  ..., -0.0311,  0.0167,  0.0620],\n","          [ 0.0403, -0.0035, -0.0169,  ..., -0.0015, -0.0204, -0.0060],\n","          [ 0.0215, -0.0476, -0.0241,  ..., -0.0152,  0.0522,  0.0387],\n","          ...,\n","          [ 0.0774,  0.0289, -0.0011,  ...,  0.0037, -0.0476,  0.0008],\n","          [-0.0217,  0.0006,  0.0043,  ..., -0.0060, -0.0353,  0.0395],\n","          [-0.0204,  0.0197,  0.0025,  ...,  0.0515, -0.0104,  0.0417]],\n","         device='cuda:0')}}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["mean_vector = isovec_multi['complexity']['mean']\n","pcs = isovec_multi['complexity']['pcs']\n","pcs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BFOSAnda3xRX","executionInfo":{"status":"ok","timestamp":1703221280472,"user_tz":300,"elapsed":151,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"6a6c57af-30d3-4436-cc83-cb9827cc11a9"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([7, 768])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["##ABTT on dvec\n","# Compute dot products of pcs with emb1_mean_rm and emb2_mean_rm\n","pc_dot1 = pcs @ (d_vec_multi - mean_vector)\n","rm_term1 = (pc_dot1[..., None] * pcs).sum(axis=0)\n","dvec_abtt = (d_vec_multi - mean_vector) - rm_term1"],"metadata":{"id":"vUvDBl3r65E3","executionInfo":{"status":"ok","timestamp":1703221281513,"user_tz":300,"elapsed":144,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["LM = AutoModel.from_pretrained('bert-base-multilingual-uncased').to(device)\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-uncased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["1873c84a63094d2f8fc4fdd2c50c36f0","6702d1cbbacd4b2a8ef80b45d8cd15b5","a53c8f7a3d354e0f91dd56a9efb34a5f","8f5a7910dbaa481f918fabe715c601b0","b1fff4dc8cb64f51a53523dbc2c56011","8f85200085a44c958835a80d4829072c","ec1c6e8fd5254f49a7c4f4ec598a7e79","989f103e6cf54941b47f9d612b9fb432","52f1a1ce29724bbbbb9bc3e8749b6db7","604abbfcccac42bc8c7901f511a3fea7","ab82c2886bf64424a9c59cee4d0704a7","204a1170e7b6474db05e7dd2ad9cb20a","e70fb4c1bf2b455983744afc71eda026","faf6e76b6bbc4a1c831779d3f3af680d","0c43c38edf054eeaac39bfc3bd71645c","c0dea67dc1b849638b09e08df2f48998","666f097e6d2041e1ab84ba5f05829475","c2bd1cc6ad0c43cebf4b80b6060ef061","00664114fd1642649974cc6347bceba0","2a426b1aca774dc0bae637f92e83d975","9315aab1b3e3460899d1416aa760f1e8","053e3a5ca9ae4824a5375d18ec40d82e","74a9a3d477c4476ca6135f079b1f5bbd","7090a2d743ca49a7836fe9e3b6c1d777","9da8879780074a3cb62b86a67830dd33","8b73ca06aee341e1b0031b8b9e8547ab","9c00f5822fac42b28e636cd5d3f2d7a2","3f186f9e030d423f827acce140cc7c79","e2860d9b389342ed9f561168ad2cfbc8","dcf716647c044886b26adb163fec2d91","f732076cad444afcbba6bf167d1b0034","6e8075b1ce79450daec16aa3ca487bb8","07eb55959fdd480aba00eb882a0b9b9b","657e9d59bb15415895b5aab36a3c21e0","ffd8a5d0a56d4845bf1ddf0d41ff58dd","ca643a81751045c58b89a9f588c1272b","42005054ce4048358d855c80e1dc0d5d","a71498ed7e964102b04d4dacc5d97a56","23fedc2483f341d8b4b4d481a106f5b3","ecda7b2ec1554095902f6316bbe5b3f9","7a59a85480be408e972c7c39e2aeb2af","0eba3fd745774ca7b73c71ef1cfb0031","27311f5eb1c6433e9e9b302bf090b0a6","2d56e222eb994e4b8b283df5b88e494c","2db2df3d02ff4e639b98ec2513568aa5","e41af63109284e7b993beada3e3fc767","d311ae0203184ae8811f427e41694988","5661d4b53a8d43c2b0167fe4f2dfdb8f","d73736dcbbb64002ae492c2b4d6c4c77","d97ed6e53d5d45218e94abd4bb4016ac","9e7eb67781ed4e409e29f8aab684ae60","1d2f70bbc0764f3aa143aa83e8a69abf","49df78b85a8041fd86da9889854a7798","e033e88e504f45c3ac5f18a6b335b3d2","5bb22748772c4deb800bd9fbff2b6ee3"]},"id":"fHQZQCUUogYN","executionInfo":{"status":"ok","timestamp":1703221293852,"user_tz":300,"elapsed":10249,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"76423b8b-24f8-4ac3-bde9-9111037638e2"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1873c84a63094d2f8fc4fdd2c50c36f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"204a1170e7b6474db05e7dd2ad9cb20a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74a9a3d477c4476ca6135f079b1f5bbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"657e9d59bb15415895b5aab36a3c21e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2db2df3d02ff4e639b98ec2513568aa5"}},"metadata":{}}]},{"cell_type":"code","source":["def get_embeddings(texts):\n","\t\tglobal LM, tokenizer\n","\t\tlayer = 4\n","\t\tlayeragg = True\n","\n","\t\tif tokenizer: # Contextualized models\n","\t\t\t# tokenize the texts\n","\t\t\tinputs = tokenizer(texts, is_split_into_words=True, padding=True, return_tensors=\"pt\", truncation=True).to(device)\n","\t\t\t# get the embeddings\n","\t\t\tLM.eval()\n","\t\t\twith torch.no_grad():\n","\t\t\t\t# process one batch at a time\n","\t\t\t\ttexts_embeddings = []\n","\t\t\t\toutputs = LM(**inputs, output_hidden_states=True)\n","\t\t\t\t# get the embeddings of the specified layer\n","\t\t\t\t# print(f\"Number of layers in {self.LM_names[feature]}: {len(outputs.hidden_states)}\")\n","\t\t\t\tif layeragg: # average embeddings from the first to the current layer\n","\t\t\t\t\tif layer == -1:\n","\t\t\t\t\t\tlayer = len(outputs.hidden_states) - 1\n","\t\t\t\t\ttoken_embeddings = torch.stack(outputs.hidden_states[:layer+1], dim=0).mean(dim=0)\n","\t\t\t\telse:\n","\t\t\t\t\ttoken_embeddings = outputs.hidden_states[layer]\n","\t\t\t\t# for each text, get the averaged token embeddings\n","\t\t\t\tfor text_id, token_embedding in enumerate(token_embeddings):\n","\t\t\t\t\t# align the token embeddings with the pre-split tokens\n","\t\t\t\t\t# if a pre-split token is then split into multiple wordpieces, average the embeddings of the wordpieces\n","\t\t\t\t\taligned_token_embedding = []\n","\t\t\t\t\ttransformer_to_presplit_word_id_mapping = inputs.word_ids(batch_index=text_id)\n","\t\t\t\t\tprevious_word_idx = -1\n","\t\t\t\t\tcurrent_token_wordpieces_embeddings = []\n","\n","\t\t\t\t\tfor transformer_token_id, presplit_word_id in enumerate(transformer_to_presplit_word_id_mapping):\n","\t\t\t\t\t\tif presplit_word_id is None:\n","\t\t\t\t\t\t\tcontinue\n","\t\t\t\t\t\telif presplit_word_id != previous_word_idx:  # new word\n","\t\t\t\t\t\t\t# add the previous token\n","\t\t\t\t\t\t\tif current_token_wordpieces_embeddings:\n","\t\t\t\t\t\t\t\tcurrent_token_wordpieces_embeddings = torch.stack(current_token_wordpieces_embeddings)\n","\t\t\t\t\t\t\t\taligned_token_embedding.append(torch.mean(current_token_wordpieces_embeddings, dim=0))\n","\t\t\t\t\t\t\t# start a new token\n","\t\t\t\t\t\t\tcurrent_token_wordpieces_embeddings = [token_embedding[transformer_token_id]]\n","\t\t\t\t\t\t\tif presplit_word_id != previous_word_idx + 1: # new token id is not continuous\n","\t\t\t\t\t\t\t\t# append zero embeddings for missing tokens\n","\t\t\t\t\t\t\t\tfor _ in range(presplit_word_id - previous_word_idx - 1):\n","\t\t\t\t\t\t\t\t\taligned_token_embedding.append(torch.zeros(LM.config.hidden_size).to(device))\n","\t\t\t\t\t\telse: # same word\n","\t\t\t\t\t\t\tcurrent_token_wordpieces_embeddings.append(token_embedding[transformer_token_id])\n","\t\t\t\t\t\tprevious_word_idx = presplit_word_id\n","\n","\t\t\t\t\t# add the last token\n","\t\t\t\t\tcurrent_token_wordpieces_embeddings = torch.stack(current_token_wordpieces_embeddings)\n","\t\t\t\t\taligned_token_embedding.append(torch.mean(current_token_wordpieces_embeddings, dim=0))\n","\t\t\t\t\tn_tokens = len(texts[text_id])\n","\t\t\t\t\tfor _ in range(n_tokens - previous_word_idx - 1):\n","\t\t\t\t\t\taligned_token_embedding.append(torch.zeros(LM.config.hidden_size).to(device))\n","\t\t\t\t\taligned_token_embedding = torch.stack(aligned_token_embedding)\n","\n","\t\t\t\t\t# add to the list of sentence embeddings\n","\t\t\t\t\ttexts_embeddings.append(aligned_token_embedding)\n","\n","\t\t\t\t# texts_embeddings = torch.stack(texts_embeddings)\n","\n","\t\telse: # Static models\n","\t\t\t# get the embeddings\n","\t\t\ttexts_embeddings = []\n","\t\t\tfor text in texts:\n","\t\t\t\ttext_embedding = []\n","\t\t\t\tfor token in text:\n","\t\t\t\t\ttoken_embedding = torch.from_numpy(get_static_embedding(LM, token).copy()).to(device)\n","\t\t\t\t\ttext_embedding.append(token_embedding)\n","\t\t\t\ttext_embedding = torch.stack(text_embedding)\n","\t\t\t\ttexts_embeddings.append(text_embedding)\n","\t\t\t# texts_embeddings = torch.stack(texts_embeddings)\n","\t\treturn texts_embeddings"],"metadata":{"id":"L8NSu9RMoiyD","executionInfo":{"status":"ok","timestamp":1703221293853,"user_tz":300,"elapsed":2,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def get_feature_batch(texts):\n","    ''' Predict the target feature for a batch of texts.\n","\n","    :param texts: a list of texts, each of which is a string.\n","    :param feature: the target feature to predict, which can be \"complexity\", \"formality\", \"intensity\", or \"figurativeness\".\n","\n","    :return: features_for_texts: a tensor of shape [n_texts, n_dim] representing the feature scores for each text, where n_dim is the dimension of the feature.\n","    '''\n","    # tokenize and POS tag the texts\n","    tokens_for_texts, pos_tags_for_texts = parse_batch(texts)\n","    features_for_texts = []\n","\n","    # get the average token embeddings as sentence embedding\n","    # get the raw token embeddings\n","    # get the average token embeddings as sentence embedding\n","    for tokens_for_text in tokens_for_texts:\n","        token_embs = get_embeddings([tokens_for_text])[0] # shape: [n_tokens, emb_dim]\n","        mean_text_emb = torch.mean(token_embs, dim=0) # shape: [emb_dim]\n","        # compute the generalized similarity between the text embedding and the dvec\n","        # cos_sim = cosine_similarity(mean_text_emb, self.dvecs[feature].unsqueeze(0)).squeeze(0)\n","        features_for_text = [mean_text_emb]\n","        features_for_text = torch.stack(features_for_text)\n","        features_for_texts.append(features_for_text)\n","    features_for_texts = torch.stack(features_for_texts)\n","    return features_for_texts"],"metadata":{"id":"L0xU5QkYok9D","executionInfo":{"status":"ok","timestamp":1703221297112,"user_tz":300,"elapsed":135,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# Train Data"],"metadata":{"id":"nfUf-3tBx4nt"}},{"cell_type":"code","source":["train_data = load_dataset(train_data_path)\n","# Make predictions\n","predicted_class = \"simple\" # we want to identify the simpler one in two texts\n","\n","text0s_train = []\n","text1s_train = []\n","gold_labels_train = []\n","for example in train_data:\n","  text0, text1, gold = example[\"0\"], example[\"1\"], example[\"gold_simple\"]\n","  text0s_train.append(text0)\n","  text1s_train.append(text1)\n","  gold_labels_train.append(int(gold))\n","  #pred = model.compare_complexity(text0=text0, text1=text1)\n","  #pred_row = example.copy()\n","  #pred_row[f\"pred_{predicted_class}\"] = pred\n","  #prediction_rows.append(pred_row)"],"metadata":{"id":"3EcxAdz3ooXG","executionInfo":{"status":"ok","timestamp":1703221299609,"user_tz":300,"elapsed":2,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["embeddings0_train = get_feature_batch(text0s_train)\n","embeddings1_train = get_feature_batch(text1s_train)\n","embeddings0_train = embeddings0_train.reshape(embeddings0_train.shape[0], -1).cpu().detach().numpy()\n","embeddings1_train = embeddings1_train.reshape(embeddings1_train.shape[0], -1).cpu().detach().numpy()"],"metadata":{"id":"idKHokmarWVO","executionInfo":{"status":"ok","timestamp":1703221463801,"user_tz":300,"elapsed":155796,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["d_vec = dvec_abtt.cpu().numpy()\n","d_vec = d_vec.reshape((1, -1))\n","d_vec.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-FnbH2cu2nP","executionInfo":{"status":"ok","timestamp":1703129997780,"user_tz":300,"elapsed":18,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"1310fc5b-a2da-442c-cc69-f958484b5237"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 768)"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["similarity_data_x = []\n","similarity_data_y = []\n","for embedding0, embedding1, label in zip(embeddings0_train, embeddings1_train, gold_labels_train):\n","  #abtt removal\n","  emb1_mean_rm = embedding0 - mean_vector.cpu().numpy()\n","  emb2_mean_rm = embedding1 - mean_vector.cpu().numpy()\n","  pc_dot1 = pcs.cpu().numpy() @ emb1_mean_rm\n","  pc_dot2 = pcs.cpu().numpy() @ emb2_mean_rm\n","  rm_term1 = (pc_dot1[..., None] * pcs.cpu().numpy()).sum(axis=0)\n","  rm_term2 = (pc_dot2[..., None] * pcs.cpu().numpy()).sum(axis=0)\n","  emb1_abtt = emb1_mean_rm - rm_term1\n","  emb2_abtt = emb2_mean_rm - rm_term2\n","  x = np.concatenate([emb1_abtt.reshape((1, -1)), emb2_abtt.reshape((1, -1)), d_vec], axis=1)\n","  similarity_data_x.append(x)\n","  similarity_data_y.append(label)"],"metadata":{"id":"Dp_qgM22sVhA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","tensor_x = torch.Tensor(similarity_data_x)\n","tensor_y = torch.Tensor(similarity_data_y)\n","\n","tensor_x = tensor_x.squeeze().type(torch.FloatTensor)\n","tensor_y = tensor_y.squeeze().type(torch.FloatTensor)\n","\n","train_dataset = TensorDataset(tensor_x,tensor_y)\n","train_dataloader = DataLoader(train_dataset, batch_size=128)"],"metadata":{"id":"j7E28gyPwg4G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensor_x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mt6ULs2r7RZd","executionInfo":{"status":"ok","timestamp":1703130000050,"user_tz":300,"elapsed":5,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"02267a51-29f1-47fd-9030-4290731cbbae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2943, 2304])"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["# Val Data"],"metadata":{"id":"WQdID3Pax9VV"}},{"cell_type":"code","source":["val_data = load_dataset(val_data_path)\n","# Make predictions\n","predicted_class = \"simple\" # we want to identify the simpler one in two texts\n","\n","text0s_val = []\n","text1s_val = []\n","gold_labels_val = []\n","for example in val_data:\n","  text0, text1, gold = example[\"0\"], example[\"1\"], example[\"gold_simple\"]\n","  text0s_val.append(text0)\n","  text1s_val.append(text1)\n","  gold_labels_val.append(int(gold))\n","  #pred = model.compare_complexity(text0=text0, text1=text1)\n","  #pred_row = example.copy()\n","  #pred_row[f\"pred_{predicted_class}\"] = pred\n","  #prediction_rows.append(pred_row)"],"metadata":{"id":"CrLg4Kk_x8TU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings0_val = get_feature_batch(text0s_val)\n","embeddings1_val = get_feature_batch(text1s_val)\n","embeddings0_val = embeddings0_val.reshape(embeddings0_val.shape[0], -1).cpu().detach().numpy()\n","embeddings1_val = embeddings1_val.reshape(embeddings1_val.shape[0], -1).cpu().detach().numpy()"],"metadata":{"id":"fcWobmhxyCVy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["similarity_data_x_val = []\n","similarity_data_y_val = []\n","for embedding0, embedding1, label in zip(embeddings0_val, embeddings1_val, gold_labels_val):\n","  #abtt removal\n","  emb1_mean_rm = embedding0 - mean_vector.cpu().numpy()\n","  emb2_mean_rm = embedding1 - mean_vector.cpu().numpy()\n","  pc_dot1 = pcs.cpu().numpy() @ emb1_mean_rm\n","  pc_dot2 = pcs.cpu().numpy() @ emb2_mean_rm\n","  rm_term1 = (pc_dot1[..., None] * pcs.cpu().numpy()).sum(axis=0)\n","  rm_term2 = (pc_dot2[..., None] * pcs.cpu().numpy()).sum(axis=0)\n","  emb1_abtt = emb1_mean_rm - rm_term1\n","  emb2_abtt = emb2_mean_rm - rm_term2\n","  x = np.concatenate([emb1_abtt.reshape((1, -1)), emb2_abtt.reshape((1, -1)), d_vec], axis=1)\n","  similarity_data_x_val.append(x)\n","  similarity_data_y_val.append(label)"],"metadata":{"id":"Y53zsfeAyU4a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensor_x_val = torch.Tensor(similarity_data_x_val)\n","tensor_y_val = torch.Tensor(similarity_data_y_val)\n","\n","tensor_x_val = tensor_x_val.squeeze().type(torch.FloatTensor)\n","tensor_y_val = tensor_y_val.squeeze().type(torch.FloatTensor)\n","\n","val_dataset = TensorDataset(tensor_x_val, tensor_y_val)\n","val_dataloader = DataLoader(val_dataset, batch_size=128)"],"metadata":{"id":"s17AorBeynyu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Test Data"],"metadata":{"id":"wLNJmsmh-kW6"}},{"cell_type":"code","source":["test_data = load_dataset(test_data_path)\n","# Make predictions\n","predicted_class = \"simple\" # we want to identify the simpler one in two texts\n","\n","text0s_test = []\n","text1s_test = []\n","gold_labels_test = []\n","for example in test_data:\n","  text0, text1, gold = example[\"0\"], example[\"1\"], example[\"gold_simple\"]\n","  text0s_test.append(text0)\n","  text1s_test.append(text1)\n","  gold_labels_test.append(int(gold))\n","  #pred = model.compare_complexity(text0=text0, text1=text1)\n","  #pred_row = example.copy()\n","  #pred_row[f\"pred_{predicted_class}\"] = pred\n","  #prediction_rows.append(pred_row)"],"metadata":{"id":"jAZFUPxU-xrm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embeddings0_test = get_feature_batch(text0s_test)\n","embeddings1_test = get_feature_batch(text1s_test)\n","embeddings0_test = embeddings0_test.reshape(embeddings0_test.shape[0], -1).cpu().detach().numpy()\n","embeddings1_test = embeddings1_test.reshape(embeddings1_test.shape[0], -1).cpu().detach().numpy()"],"metadata":{"id":"32zMI-0v_Bpd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["similarity_data_x_test = []\n","similarity_data_y_test = []\n","for embedding0, embedding1, label in zip(embeddings0_test, embeddings1_test, gold_labels_test):\n","  #abtt removal\n","  emb1_mean_rm = embedding0 - mean_vector.cpu().numpy()\n","  emb2_mean_rm = embedding1 - mean_vector.cpu().numpy()\n","  pc_dot1 = pcs.cpu().numpy() @ emb1_mean_rm\n","  pc_dot2 = pcs.cpu().numpy() @ emb2_mean_rm\n","  rm_term1 = (pc_dot1[..., None] * pcs.cpu().numpy()).sum(axis=0)\n","  rm_term2 = (pc_dot2[..., None] * pcs.cpu().numpy()).sum(axis=0)\n","  emb1_abtt = emb1_mean_rm - rm_term1\n","  emb2_abtt = emb2_mean_rm - rm_term2\n","  x = np.concatenate([emb1_abtt.reshape((1, -1)), emb2_abtt.reshape((1, -1)), d_vec], axis=1)\n","  similarity_data_x_test.append(x)\n","  similarity_data_y_test.append(label)"],"metadata":{"id":"0hAA7HAc_mlA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tensor_x_test = torch.Tensor(similarity_data_x_test)\n","tensor_y_test = torch.Tensor(similarity_data_y_test)\n","\n","tensor_x_test = tensor_x_test.squeeze().type(torch.FloatTensor)\n","tensor_y_test = tensor_y_test.squeeze().type(torch.FloatTensor)\n","\n","test_dataset = TensorDataset(tensor_x_test, tensor_y_test)\n","test_dataloader = DataLoader(test_dataset, batch_size=128)"],"metadata":{"id":"g9By3XOw_zzT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Neural Network"],"metadata":{"id":"IWzHGq9z-mq9"}},{"cell_type":"code","source":["# simple neural network\n","class Network(nn.Module):\n","    def __init__(self, in_dim, out_dim):\n","        super().__init__()\n","\n","        # Start of the implementation\n","        self.fc1 = torch.nn.Linear(in_dim, 3000)\n","        self.relu = torch.nn.functional.relu\n","        self.fc2 = torch.nn.Linear(3000, out_dim)\n","        # End of the implementation\n","\n","    def forward(self, x):\n","        # Start of the implementation\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x\n","        # End of the implementation"],"metadata":{"id":"NrDmlm49nnIe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def evaluate(model, loader):\n","    \"\"\"\n","    Evaluate the model accuracy on the training/test set by looping over the data loader.\n","\n","    Args:\n","        model: a neural network\n","        loader: a PyTorch data loader\n","\n","    Returns:\n","        (a float scalar) the accuracy on the training/test set\n","    \"\"\"\n","    model.eval()\n","\n","    correct = 0.\n","    total = 0.\n","\n","    for x, y in loader:\n","        # Start of the implementation\n","        output = model(x)\n","        preds = torch.round(torch.sigmoid(output))\n","        num_correct = torch.eq(y.reshape((-1, 1)), preds).sum().item()\n","        num_total = preds.shape[0]\n","        correct += num_correct\n","        total += num_total\n","        # End of the implementation\n","\n","    return correct / total\n","\n","\n","def train(model, optimizer, train_loader, test_loader, epoch=20):\n","    \"\"\"\n","    Train the neural network.\n","\n","    Args:\n","        model: a neural network\n","        train_loader: a PyTorch data loader on the training set\n","        test_loader: a PyTorch data loader on the test set\n","        epoch: the number of epochs\n","\n","    Returns:\n","        None, the model is updated in-place\n","    \"\"\"\n","    model.train()\n","\n","    # we use the cross entropy loss for classification\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    # Start of the implementation\n","    for i in range(epoch):\n","      for x, y in train_loader:\n","        output = model(x)\n","        loss = criterion(output, y.reshape((-1, 1)))\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","      if i % 5 == 0:\n","        print(loss.item(), evaluate(model, train_loader))\n","    # End of the implementation\n"],"metadata":{"id":"zvmO2czwnwFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["similarity_nn = Network(768*3, 1)\n","# 3*758 input: (embedding0, embedding1, d_vev) output: 0/1\n","# use adam"],"metadata":{"id":"7wGpjHM-xhqM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["similarity_nn = Network(768*3, 1)\n","\n","optimizer = torch.optim.Adam(similarity_nn.parameters(), lr=0.0001)\n","\n","train(similarity_nn, optimizer, train_dataloader, val_dataloader, epoch=40)\n","\n","acc_train_set = evaluate(similarity_nn, train_dataloader)\n","acc_test_set = evaluate(similarity_nn, val_dataloader)\n","\n","print(\"training set acc {:f}, test set acc {:f}\".format(acc_train_set, acc_test_set))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnT7YSqUaDAj","executionInfo":{"status":"ok","timestamp":1703130188344,"user_tz":300,"elapsed":93055,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"ec913958-d4a8-475a-a74d-0760c2beba10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6580907702445984 0.5966700645599728\n","0.41017475724220276 0.8685015290519877\n","0.20767317712306976 0.9561671763506626\n","0.0991060882806778 0.9836901121304791\n","0.061404645442962646 0.9870880054366293\n","0.04418423771858215 0.9612640163098879\n","0.030573390424251556 0.9398572884811417\n","0.029435446485877037 0.9758749575263337\n","training set acc 0.919130, test set acc 0.742015\n"]}]},{"cell_type":"code","source":["evaluate(similarity_nn, test_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQi7aYy4Ak70","executionInfo":{"status":"ok","timestamp":1703130188345,"user_tz":300,"elapsed":22,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"51d9de8d-3a91-4c81-e2d6-c3031bfafad4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6850180505415162"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["#Random forest"],"metadata":{"id":"F958Pl-Xd3XK"}},{"cell_type":"code","source":["len(similarity_data_x_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IP6OLXZkA6KD","executionInfo":{"status":"ok","timestamp":1703130188345,"user_tz":300,"elapsed":19,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"d0b93855-4a82-4261-e874-04d2b2d3a50c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1108"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","\n","clf = RandomForestClassifier(max_depth=2, random_state=0)\n","\n","clf.fit(np.array(similarity_data_x).reshape((2943, 2304)), similarity_data_y)\n","\n","preds = clf.predict(np.array(similarity_data_x_val).reshape((814, 2304)))\n","\n","clf.score(np.array(similarity_data_x_val).reshape((814, 2304)), similarity_data_y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czVlY9UId9V6","executionInfo":{"status":"ok","timestamp":1703130191068,"user_tz":300,"elapsed":2740,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"0cdf3729-1f22-4399-bbd6-669bf27e002f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4975429975429975"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["clf.score(np.array(similarity_data_x_test).reshape((1108, -1)), similarity_data_y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nnwc9ZrlAxk0","executionInfo":{"status":"ok","timestamp":1703130191068,"user_tz":300,"elapsed":3,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"9ab9133d-c4a1-472c-c824-431dcfd9c778"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4503610108303249"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["#Gradient Boost"],"metadata":{"id":"pNxIfeA-gTPd"}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","\n","clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0)\n","\n","clf.fit(np.array(similarity_data_x).reshape((2943, 2304)), similarity_data_y)\n","\n","preds = clf.predict(np.array(similarity_data_x_val).reshape((814, 2304)))\n","\n","clf.score(np.array(similarity_data_x_val).reshape((814, 2304)), similarity_data_y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"476rXbnQgIK5","executionInfo":{"status":"ok","timestamp":1703130244815,"user_tz":300,"elapsed":53749,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"902d6035-dcfb-4c4e-c228-891767ec09e8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5307125307125307"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["clf.score(np.array(similarity_data_x_test).reshape((1108, 2304)), similarity_data_y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibAeMNaWBTYN","executionInfo":{"status":"ok","timestamp":1703130244815,"user_tz":300,"elapsed":18,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"4271a380-a204-47df-a51d-773df3aea25b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4963898916967509"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["#Adaboost"],"metadata":{"id":"j91YfCdehOfp"}},{"cell_type":"code","source":["from sklearn.ensemble import AdaBoostClassifier\n","\n","clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n","\n","clf.fit(np.array(similarity_data_x).reshape((2943, 2304)), similarity_data_y)\n","\n","preds = clf.predict(np.array(similarity_data_x_val).reshape((814, 2304)))\n","\n","clf.score(np.array(similarity_data_x_val).reshape((814, 2304)), similarity_data_y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M0nnSxs0hcpK","executionInfo":{"status":"ok","timestamp":1703130304411,"user_tz":300,"elapsed":59611,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"db23b0d7-844f-4f21-e418-103c05a5f0d7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6560196560196561"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["clf.score(np.array(similarity_data_x_test).reshape((1108, 2304)), similarity_data_y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HnaTEMD_Br-S","executionInfo":{"status":"ok","timestamp":1703130304411,"user_tz":300,"elapsed":3,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"61185bc7-3b0b-4d7a-845f-c40cdfe7e160"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6128158844765343"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["#SVM (rbf kernel)"],"metadata":{"id":"i8UgM1TPgew-"}},{"cell_type":"code","source":["from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n","\n","clf.fit(np.array(similarity_data_x).reshape((2943, 2304)), similarity_data_y)\n","\n","preds = clf.predict(np.array(similarity_data_x_val).reshape((814, 2304)))\n","\n","clf.score(np.array(similarity_data_x_val).reshape((814, 2304)), similarity_data_y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMZ0cHBMgkVf","executionInfo":{"status":"ok","timestamp":1703130327206,"user_tz":300,"elapsed":22797,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"2495c124-c4b2-4a3d-a729-6b710c4f97dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7162162162162162"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["clf.score(np.array(similarity_data_x_test).reshape((1108, 2304)), similarity_data_y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_uerD96B29U","executionInfo":{"status":"ok","timestamp":1703130334886,"user_tz":300,"elapsed":7682,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"49e05c92-e6bb-40ca-ad14-dd4f234bf8c5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6236462093862816"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","source":["#SVM (poly kernel)"],"metadata":{"id":"wJHgCf5ZhuRQ"}},{"cell_type":"code","source":["from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","clf = make_pipeline(StandardScaler(), SVC(gamma='auto', kernel = 'sigmoid'))\n","\n","clf.fit(np.array(similarity_data_x).reshape((2943, 2304)), similarity_data_y)\n","\n","preds = clf.predict(np.array(similarity_data_x_val).reshape((814, 2304)))\n","\n","clf.score(np.array(similarity_data_x_val).reshape((814, 2304)), similarity_data_y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L8_6RUreh-LO","executionInfo":{"status":"ok","timestamp":1703130350910,"user_tz":300,"elapsed":16056,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"bf690dbe-2b2e-4bf8-e357-e4f3eff375c1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.714987714987715"]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["clf.score(np.array(similarity_data_x_test).reshape((1108, 2304)), similarity_data_y_test)"],"metadata":{"id":"gL9ILpBUCB9l","executionInfo":{"status":"ok","timestamp":1703130354426,"user_tz":300,"elapsed":3533,"user":{"displayName":"Cassie Huang","userId":"15857005470690603327"}},"outputId":"741dabb2-48db-409a-98c6-f3f00e761354","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6398916967509025"]},"metadata":{},"execution_count":56}]}]}